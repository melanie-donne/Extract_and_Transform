from pyspark.sql.types import StructType, StructField, StringType, IntegerType

import pandas as pd

​

df = pd.read_json('voitures.json')

print(df.head(5))

​

def extract():

    passages_logs_df = spark.read.csv("passages.logs", sep="/", schema=StructType([

        StructField("identifiant", StringType(), True),

        StructField("date", StringType(), True),

        StructField("immatriculation", StringType(), True),

        StructField("vitesse", StringType(), True)

    ]))

​

    voitures_json_df = spark.read.json("voitures.json", schema=StructType([

        StructField("immatriculation", StringType(), True),

        StructField("location", StructType([

            StructField("address", StringType(), True),

            StructField("city", StringType(), True),

            StructField("state", StringType(), True),

            StructField("zipcode", StringType(), True)

        ]), True),

        StructField("name", StringType(), True),

        StructField("phone", StringType(), True),

        StructField("points", IntegerType(), True)

    ]), mode="PERMISSIVE")

​

​

    passages_logs_df = passages_logs_df.dropDuplicates().na.drop()

    voitures_json_df = voitures_json_df.dropDuplicates().na.drop()

​

    amendes_csv_df = spark.read.csv("amendes.csv", header=True, inferSchema=True)

    amendes_csv_df = amendes_csv_df.dropDuplicates().na.drop()

​

    return passages_logs_df, voitures_json_df, amendes_csv_df

​

passages_logs_df, voitures_json_df, amendes_csv_df = extract()

​

# Affichage des schémas et des premières lignes des DataFrames

print("Schéma de passages_logs_df :")

passages_logs_df.printSchema()

print("Schéma de voitures_json_df :")

voitures_json_df.printSchema()

print("Schéma de amendes_csv_df :")

amendes_csv_df.printSchema()

​

print("Premières lignes de passages_logs_df :")

passages_logs_df.show(5)

print("Premières lignes de voitures_json_df :")

voitures_json_df.show(5)

print("Premières lignes de amendes_csv_df :")

amendes_csv_df.show(5)

  immatriculation               name  \
0         SC404KK  Frances Sevillano   
1         ZN773WQ    Vanessa Montoya   
2         NN960TY    Candice Johnson   
3         YG378VR       Tommie Eguia   
4         RA441MQ     Patricia Smith   

                                            location       phone  points  
0  {'address': '7700 Morningside Drive Northwest'...  O741783877      12  
1  {'address': '618 McLaws Street', 'city': 'Sava...  O772044156       7  
2  {'address': '711 Tatem Street', 'city': 'Savan...  0695748051       4  
3  {'address': '5130 Morris Way', 'city': 'Fremon...  O787379654       9  
4  {'address': '2068 Happy Lane', 'city': 'Crofto...  O714159726       8  
Schéma de passages_logs_df :
root
 |-- identifiant: string (nullable = true)
 |-- date: string (nullable = true)
 |-- immatriculation: string (nullable = true)
 |-- vitesse: string (nullable = true)

Schéma de voitures_json_df :
root
 |-- immatriculation: string (nullable = true)
 |-- location: struct (nullable = true)
 |    |-- address: string (nullable = true)
 |    |-- city: string (nullable = true)
 |    |-- state: string (nullable = true)
 |    |-- zipcode: string (nullable = true)
 |-- name: string (nullable = true)
 |-- phone: string (nullable = true)
 |-- points: integer (nullable = true)

Schéma de amendes_csv_df :
root
 |-- _c0: integer (nullable = true)
 |-- borne_basse: integer (nullable = true)
 |-- borne_haute: integer (nullable = true)
 |-- amende: integer (nullable = true)
 |-- points: integer (nullable = true)

Premières lignes de passages_logs_df :
+-----------+----+---------------+-----------+
|identifiant|date|immatriculation|    vitesse|
+-----------+----+---------------+-----------+
|   1239300 |  09|             02|2022 19:27 |
|   1239379 |  28|             02|2022 23:55 |
|   1239399 |  27|             02|2022 00:02 |
|   1239664 |  01|             04|2022 03:18 |
|   1239729 |  24|             08|2022 15:37 |
+-----------+----+---------------+-----------+
only showing top 5 rows

Premières lignes de voitures_json_df :
+---------------+--------+----+-----+------+
|immatriculation|location|name|phone|points|
+---------------+--------+----+-----+------+
+---------------+--------+----+-----+------+

Premières lignes de amendes_csv_df :
+---+-----------+-----------+------+------+
|_c0|borne_basse|borne_haute|amende|points|
+---+-----------+-----------+------+------+
|  2|         30|         50|   235|     4|
|  3|         50|        200|   450|    12|
|  0|          0|         20|    90|     1|
|  1|         20|         30|   135|     2|
+---+-----------+-----------+------+------+

Transform

    Dans cette partie, l'objectif est de créer un DataFrame unique permettant par la suite d'envoyer les amendes et de retirer les points nécessaires aux conducteurs ayant roulé trop vite sur l'autoroute (i.e. une vitesse strictement supérieure à 130 km/h).

    Les colonnes que l'on cherche à avoir sont les suivantes:

        immatriculation: colonne identifiant un véhicule
        to_pay: somme de toutes les amendes à payer pour cette voiture
        points_perdus: somme des points perdus par cette voiture
        points : nombre de points que la personne associée à cette voiture avait
        retrait_permis : booléen qui vaut True si la personne n'a plus de points sur son permis

    (c) Définir une fonction transform réalisant la jointure entre les différents DataFrames et donnant le DataFrame final souhaité.

  On pourra utiliser join avec une condition d'égalité sur l'immatriculation pour passages et voitures et utiliser une double inégalité pour la condition avec amendes.

from pyspark.sql.functions import col, expr

​

def transform(passages_logs_df, voitures_json_df, amendes_csv_df):

    # Join entre passages_logs_df et voitures_json_df sur la colonne 'immatriculation'

    df = passages_logs_df.join(voitures_json_df, "immatriculation")

​

    # Calcul des amendes à payer en fonction de la vitesse enregistrée

    df = df.join(amendes_csv_df, (df["vitesse"] > amendes_csv_df["borne_basse"]) & 

                                  (df["vitesse"] <= amendes_csv_df["borne_haute"]))

​

    # Calcul des amendes à payer

    df = df.withColumn("to_pay", expr("CASE WHEN vitesse > 130 THEN amende ELSE 0 END"))

​

    # Calcul de la somme des amendes à payer pour chaque véhicule

    df = df.groupBy("immatriculation").agg({"to_pay": "sum"}).withColumnRenamed("sum(to_pay)", "to_pay")

​

    # Calcul du nombre total de points perdus par chaque véhicule

    df = df.withColumn("points_perdus", expr("to_pay / 100"))  # Supposons que chaque 100 euros d'amende équivaut à la perte d'un point

​

    # Jointure avec le DataFrame voitures_json_df pour récupérer le nombre de points initial de chaque conducteur

    df = df.join(voitures_json_df.select("immatriculation", "points"), "immatriculation")

​

    # Calcul de la colonne 'retrait_permis' en fonction du nombre de points restants

    df = df.withColumn("retrait_permis", col("points") - col("points_perdus") <= 0)

​

    return df

​

# Utilisation de la fonction transform

final_df = transform(passages_logs_df, voitures_json_df, amendes_csv_df)

​

print("Test :")

final_df.show(5)

Test :
+---------------+------+-------------+------+--------------+
|immatriculation|to_pay|points_perdus|points|retrait_permis|
+---------------+------+-------------+------+--------------+
+---------------+------+-------------+------+--------------+

Vérification

    Nous allons tester le bon fonctionnement du code ci dessus.

    (d) Exécuter la cellule suivante.

passages, voitures, amendes = extract()

df = transform(passages, voitures, amendes)

​

display(df.limit(50).toPandas())

	immatriculation 	to_pay 	points_perdus 	points 	retrait_permis